# ğŸ”¬ Automated Detection of *Trypanosoma cruzi* in Microscopy Images

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> Automatic detection of *Trypanosoma cruzi* parasites in microscopy images using Deep Learning with Transfer Learning (VGG16 and MobileNetV2).

---

## ğŸ“‹ Table of Contents

- [About](#about)
- [Problem & Motivation](#problem--motivation)
- [Dataset](#dataset)
- [Methodology](#methodology)
- [Model Architectures](#model-architectures)
- [Results](#results)
- [Project Structure](#project-structure)
- [How to Use](#how-to-use)
- [Requirements](#requirements)
- [Challenges & Solutions](#challenges--solutions)
- [Future Work](#future-work)
- [Author](#author)

---

## ğŸ¯ About

This project implements a **binary classification system** to automatically detect the presence of *Trypanosoma cruzi* parasites in microscopy images. *T. cruzi* is the causative agent of Chagas disease, a neglected tropical disease affecting millions of people in the Americas.

The goal is to assist healthcare professionals in rapid and accurate diagnosis through **artificial intelligence**, reducing manual analysis time and increasing detection accuracy.

### âœ¨ Highlights

- ğŸ† **AUC of 0.989** on validation set
- ğŸ“Š **Average accuracy of 93.8%** on real test data
- ğŸ¯ **Sensitivity of 94.2%** (parasite detection rate)
- âœ… **Specificity of 92.7%** (low false positive rate)
- ğŸš€ Comparison between VGG16 and MobileNetV2
- ğŸ’ª Robust overfitting solution through regularization techniques

---

## ğŸ” Problem & Motivation

### Clinical Challenge

Traditional *T. cruzi* detection requires:
- â±ï¸ Time-consuming manual analysis by specialized microscopists
- ğŸ‘ï¸ High level of attention and expertise
- ğŸ”¬ Identification of small parasites (~20Î¼m) in large samples
- âš ï¸ Risk of false negatives in low parasitemia cases

### Proposed Solution

A deep learning model that:
- âœ… Automates initial slide screening
- âœ… Reduces analysis time
- âœ… Maintains high sensitivity to avoid missing positive cases
- âœ… Provides decision support for healthcare professionals

---

## ğŸ“Š Dataset

### Characteristics

- **Resolution:** 224Ã—224 pixels
- **Classes:** 
  - `Positive (1)`: Presence of *T. cruzi*
  - `Negative (0)`: Absence of parasite
- **Split:**
  - ğŸ‹ï¸ Train: ~1,600 images
  - ğŸ“ Validation: ~700 images
  - ğŸ§ª Test: 5 independent slides (18, 19, 20, 23, 24)

### Preprocessing

```python
# Normalization with ImageNet statistics
transforms.Normalize(
    mean=[0.485, 0.456, 0.406],
    std=[0.229, 0.224, 0.225]
)
```

### Data Augmentation (On-the-fly)

To increase model robustness, we apply random transformations during training:

- â†”ï¸ Horizontal and vertical flip (p=0.5)
- ğŸ”„ Random rotation (Â±15Â°)
- ğŸ“ Affine transformation (translation, scale, shear)
- ğŸ¨ Color jitter (brightness, contrast, saturation, hue)
- âœ‚ï¸ Random crop with scale 0.8-1.0

---

## ğŸ§  Methodology

### 1. Transfer Learning

We use ImageNet pre-trained models as feature extractors:
- **VGG16**: 138M parameters, classic and robust architecture
- **MobileNetV2**: 3.5M parameters, efficient for mobile devices

### 2. Feature Freezing

```python
# Freeze convolutional layers
for param in model.features.parameters():
    param.requires_grad = False
```

**Rationale:** With only ~1,600 training images, training all layers would cause severe overfitting.

### 3. Classifier Architecture

```python
model.classifier = nn.Sequential(
    nn.Linear(n_features, 256),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5),
    nn.Linear(256, 1)
)
```

**Simplified design** to prevent overfitting on small datasets.

### 4. Optimization & Regularization

| Technique | Value | Rationale |
|---------|-------|-----------|
| **Optimizer** | AdamW | Better than Adam for regularization |
| **Learning Rate** | 5Ã—10â»âµ | Balance between convergence and stability |
| **Weight Decay** | 1Ã—10â»â´ | L2 regularization |
| **Dropout** | 0.5 | Prevents neuron co-adaptation |
| **Batch Size** | 32 | Compromise between memory and convergence |

### 5. Training Strategies

- **Early Stopping:** Patience of 7 epochs to prevent overfitting
- **Learning Rate Scheduler:** ReduceLROnPlateau (reduces LR when val_loss plateaus)
- **Loss Function:** BCEWithLogitsLoss (numerically stable)

---

## ğŸ—ï¸ Model Architectures

### VGG16

**Features:**
- ğŸ“¦ 138 million parameters
- ğŸ¯ Classic and well-established architecture
- ğŸ”§ Deep convolutional layers (13 conv + 3 FC)

**Advantages:**
- âœ… High learning capacity
- âœ… Robust features for classification
- âœ… Extensively studied and tested

**Disadvantages:**
- âš ï¸ Heavy model (>500MB)
- âš ï¸ Slower inference

### MobileNetV2

**Features:**
- ğŸ“¦ 3.5 million parameters
- ğŸš€ Optimized for efficiency
- ğŸ”§ Depthwise separable convolutions

**Advantages:**
- âœ… Lightweight model (~14MB)
- âœ… Fast inference
- âœ… Ideal for mobile devices

**Disadvantages:**
- âš ï¸ Lower capacity than VGG16
- âš ï¸ May have slightly lower performance

---

## ğŸ“ˆ Results

### VGG16 - Validation Metrics

- **AUC-ROC:** 0.989
- **Best Val Loss:** 0.2763
- **Epochs trained:** 29 (early stopping)

### VGG16 - Real Test Performance

| Slide | Samples | Accuracy | Sensitivity | Specificity | TP | FP | TN | FN |
|-------|---------|----------|-------------|-------------|----|----|----|----|
| **18** | 320 | **86.3%** | 75.6% | **98.7%** | 130 | 2 | 146 | 42 |
| **19** | 167 | **94.6%** | **98.9%** | 90.0% | 86 | 8 | 72 | 1 |
| **20** | 248 | **93.2%** | 96.9% | 89.1% | 125 | 13 | 106 | 4 |
| **23** | 230 | **97.8%** | **100%** | 95.8% | 112 | 5 | 113 | 0 |
| **24** | 936 | **97.4%** | **99.8%** | 95.2% | 457 | 23 | 455 | 1 |
| **Average** | - | **93.8%** | **94.2%** | **92.7%** | - | - | - | - |

### ğŸ“Š Results Interpretation

**ğŸ¯ Sensitivity (Recall) - 94.2%:**
- Model detects **94 out of 100** parasites present
- Crucial for diagnosis: **few false negatives**
- Slide 23: 100% detection rate!

**âœ… Specificity - 92.7%:**
- Model correctly identifies **93 out of 100** negative samples
- Reduces manual review workload for false positives
- Slide 18: 98.7% - excellent reliability

**ğŸ“ˆ Overall Accuracy - 93.8%:**
- Consistent performance across 4 out of 5 slides (>93%)
- Slide 18: 86.3% (possibly different characteristics)

### ğŸ† Highlights by Slide

- **Slide 23:** Perfect performance (100% sensitivity, 0 false negatives)
- **Slide 24:** Largest dataset (936 samples), maintained 99.8% sensitivity
- **Slide 18:** 98.7% specificity (only 2 false positives)

### MobileNetV2 - Results

> ğŸš§ **Under development** - Results will be added soon

---

## ğŸ“ Project Structure

```
Projeto-Trypanossoma/
â”‚
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Project dependencies
â”œâ”€â”€ LICENSE                            # MIT License
â”‚
â”œâ”€â”€ data/                              # Data (10MB, included in repo)
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ positivo/
â”‚   â”‚   â””â”€â”€ negativo/
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ positivo/
â”‚   â”‚   â””â”€â”€ negativo/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ lamina_18/
â”‚       â”œâ”€â”€ lamina_19/
â”‚       â”œâ”€â”€ lamina_20/
â”‚       â”œâ”€â”€ lamina_23/
â”‚       â””â”€â”€ lamina_24/
â”‚
â”œâ”€â”€ models/                            # Trained models
â”‚   â”œâ”€â”€ vgg16_best_model.pth
â”‚   â””â”€â”€ mobilenetv2_best_model.pth
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_vgg16_training.ipynb
â”‚   â””â”€â”€ 03_mobilenetv2_training.ipynb
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py                     # Dataset and DataLoader
â”‚   â”œâ”€â”€ models.py                      # Model definitions
â”‚   â”œâ”€â”€ train.py                       # Training loop
â”‚   â”œâ”€â”€ evaluate.py                    # Evaluation and metrics
â”‚   â””â”€â”€ utils.py                       # Utility functions
â”‚
â”œâ”€â”€ results/                           # Results and visualizations
â”‚   â”œâ”€â”€ training_curves/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â””â”€â”€ roc_curves/
â”‚
â””â”€â”€ docs/                              # Additional documentation
    â””â”€â”€ methodology.md
```

---

## ğŸš€ How to Use

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/Projeto-Trypanossoma.git
cd Projeto-Trypanossoma
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Dataset

The complete dataset (10MB) is **included in this repository** for reproducibility.

### 4. Train the Model

#### VGG16

```bash
python src/train.py --model vgg16 --epochs 50 --batch-size 32 --lr 5e-5
```

#### MobileNetV2

```bash
python src/train.py --model mobilenetv2 --epochs 50 --batch-size 32 --lr 5e-5
```

### 5. Evaluate on Test Set

```bash
python src/evaluate.py --model vgg16 --checkpoint models/vgg16_best_model.pth --test-dir data/test/
```

### 6. Make Predictions on New Images

```python
from src.models import load_model
from src.utils import predict_image

model = load_model('vgg16', 'models/vgg16_best_model.pth')
result = predict_image(model, 'path/to/image.jpg')

print(f"Prediction: {'Positive' if result > 0.5 else 'Negative'}")
print(f"Confidence: {result:.2%}")
```

---

## ğŸ“¦ Requirements

```txt
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
Pillow>=9.5.0
tqdm>=4.65.0
```

**System:**
- Python 3.8+
- CUDA 11.8+ (optional, for GPU)
- 8GB RAM minimum (16GB recommended)

---

## ğŸ’¡ Challenges & Solutions

### ğŸ”¥ Challenge 1: Severe Overfitting

**Symptoms:**
- Train loss decreasing, but validation loss increasing
- Growing gap between training and validation

**Identified Causes:**
1. âŒ Pre-generated augmented dataset (fixed images)
2. âŒ BatchNorm with small dataset causing noise
3. âŒ Learning rate too high (1e-4)
4. âŒ All VGG layers trainable

**Implemented Solutions:**
1. âœ… On-the-fly data augmentation (infinite variations)
2. âœ… Removed BatchNorm from classifier
3. âœ… Reduced learning rate to 5e-5
4. âœ… Froze VGG features
5. âœ… Simplified classifier (512 â†’ 256 features)
6. âœ… Dropout of 0.5
7. âœ… Weight decay of 1e-4

**Result:**
- Stable val loss converging with train loss
- Minimal gap between curves
- AUC of 0.989

### ğŸ› Challenge 2: Label Misalignment

**Symptom:**
- Inconsistent and unexpected results

**Cause:**
- Labels and images in different orders

**Solution:**
```python
# Use DataFrames to ensure alignment
df = pd.DataFrame({
    'filename': sorted(image_paths),
    'label': corresponding_labels
})
```

### âš¡ Challenge 3: Slow Convergence

**Symptom:**
- Model not improving after several epochs

**Cause:**
- Learning rate too low (1e-5) with BatchNorm

**Solution:**
- Learning rate scheduler (ReduceLROnPlateau)
- Start with higher LR (5e-5), reduce when plateauing

---

## ğŸ”® Future Work

- [ ] Implement and compare MobileNetV2
- [ ] Test other architectures (ResNet, EfficientNet)
- [ ] Implement model ensemble
- [ ] Create web interface with Gradio/Streamlit
- [ ] Parasite segmentation (exact localization)
- [ ] Automatic parasitemia quantification
- [ ] Detection of other protozoa
- [ ] Mobile device deployment (TFLite/ONNX)
- [ ] Explainability with Grad-CAM
- [ ] Dataset augmentation with GAN techniques

---

## ğŸ“š References

1. World Health Organization. (2023). Chagas disease (American trypanosomiasis)
2. Simonyan, K., & Zisserman, A. (2014). Very Deep Convolutional Networks for Large-Scale Image Recognition
3. Sandler, M., et al. (2018). MobileNetV2: Inverted Residuals and Linear Bottlenecks
4. He, K., et al. (2016). Deep Residual Learning for Image Recognition

---

## ğŸ‘¨â€ğŸ’» Author

**[Your Name]**

- ğŸ“ PhD Candidate in [Your Field]
- ğŸ’¼ LinkedIn: [your-linkedin](https://linkedin.com/in/your-profile)
- ğŸ“§ Email: your.email@example.com
- ğŸ™ GitHub: [@your-username](https://github.com/your-username)

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Dataset provided by [Institution/Laboratory]
- Computational infrastructure: [GPU/Cloud provider]
- Advisor: [Advisor name]

---

## ğŸ“Š Project Status

![Status](https://img.shields.io/badge/Status-Active-success)

**Last update:** January 2026

---

## ğŸ‡§ğŸ‡· Portuguese Version

[DocumentaÃ§Ã£o em portuguÃªs disponÃ­vel aqui](README-pt.md)

---

<div align="center">

**â­ If this project was useful to you, please consider giving it a star!**

Made with â¤ï¸ and ğŸ Python

</div>
