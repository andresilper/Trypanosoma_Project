# ğŸ”¬ ClassificaÃ§Ã£o AutomÃ¡tica de *Trypanosoma cruzi* em Imagens de Microscopia

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> DetecÃ§Ã£o automÃ¡tica do parasita *Trypanosoma cruzi* em imagens de microscopia utilizando Deep Learning com Transfer Learning (VGG16 e MobileNetV2).

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Problema e MotivaÃ§Ã£o](#problema-e-motivaÃ§Ã£o)
- [Dataset](#dataset)
- [Metodologia](#metodologia)
- [Arquiteturas Comparadas](#arquiteturas-comparadas)
- [Resultados](#resultados)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Como Usar](#como-usar)
- [Requisitos](#requisitos)
- [Desafios e SoluÃ§Ãµes](#desafios-e-soluÃ§Ãµes)
- [Trabalhos Futuros](#trabalhos-futuros)
- [Autor](#autor)

---

## ğŸ¯ Sobre o Projeto

Este projeto implementa um **sistema de classificaÃ§Ã£o binÃ¡ria** para detectar automaticamente a presenÃ§a do parasita *Trypanosoma cruzi* em imagens de microscopia. O *T. cruzi* Ã© o agente causador da DoenÃ§a de Chagas, uma doenÃ§a tropical negligenciada que afeta milhÃµes de pessoas nas AmÃ©ricas.

O objetivo Ã© auxiliar profissionais de saÃºde no diagnÃ³stico rÃ¡pido e preciso atravÃ©s de **inteligÃªncia artificial**, reduzindo o tempo de anÃ¡lise manual e aumentando a acurÃ¡cia na detecÃ§Ã£o.

### âœ¨ Destaques

- ğŸ† **AUC de 0.989** no conjunto de validaÃ§Ã£o
- ğŸ“Š **AcurÃ¡cia mÃ©dia de 93.8%** em dados de teste reais
- ğŸ¯ **Sensibilidade de 94.2%** (detecÃ§Ã£o de parasitas)
- âœ… **Especificidade de 92.7%** (baixo Ã­ndice de falsos positivos)
- ğŸš€ ComparaÃ§Ã£o entre VGG16 e MobileNetV2
- ğŸ’ª SoluÃ§Ã£o robusta de overfitting atravÃ©s de tÃ©cnicas de regularizaÃ§Ã£o

---

## ğŸ” Problema e MotivaÃ§Ã£o

### Desafio ClÃ­nico

A detecÃ§Ã£o de *T. cruzi* tradicionalmente requer:
- â±ï¸ AnÃ¡lise manual demorada por microscopistas especializados
- ğŸ‘ï¸ Alto nÃ­vel de atenÃ§Ã£o e experiÃªncia
- ğŸ”¬ IdentificaÃ§Ã£o de parasitas pequenos (~20Î¼m) em grandes amostras
- âš ï¸ Risco de falsos negativos em casos de baixa parasitemia

### SoluÃ§Ã£o Proposta

Um modelo de deep learning que:
- âœ… Automatiza a triagem inicial de lÃ¢minas
- âœ… Reduz tempo de anÃ¡lise
- âœ… MantÃ©m alta sensibilidade para nÃ£o perder casos positivos
- âœ… Fornece suporte Ã  decisÃ£o para profissionais de saÃºde

---

## ğŸ“Š Dataset

### CaracterÃ­sticas

- **ResoluÃ§Ã£o:** 224Ã—224 pixels
- **Classes:** 
  - `Positivo (1)`: PresenÃ§a de *T. cruzi*
  - `Negativo (0)`: AusÃªncia do parasita
- **DivisÃ£o:**
  - ğŸ‹ï¸ Treino: ~1.600 imagens
  - ğŸ“ ValidaÃ§Ã£o: ~700 imagens
  - ğŸ§ª Teste: 5 lÃ¢minas independentes (18, 19, 20, 23, 24)

### PrÃ©-processamento

```python
# NormalizaÃ§Ã£o com estatÃ­sticas da ImageNet
transforms.Normalize(
    mean=[0.485, 0.456, 0.406],
    std=[0.229, 0.224, 0.225]
)
```

### Data Augmentation (On-the-fly)

Para aumentar a robustez do modelo, aplicamos transformaÃ§Ãµes aleatÃ³rias durante o treinamento:

- â†”ï¸ Flip horizontal e vertical (p=0.5)
- ğŸ”„ RotaÃ§Ã£o aleatÃ³ria (Â±15Â°)
- ğŸ“ TransformaÃ§Ã£o afim (translaÃ§Ã£o, escala, cisalhamento)
- ğŸ¨ VariaÃ§Ã£o de brilho, contraste, saturaÃ§Ã£o e matiz
- âœ‚ï¸ Random crop com escala 0.8-1.0

---

## ğŸ§  Metodologia

### 1. Transfer Learning

Utilizamos modelos prÃ©-treinados na ImageNet como extratores de features:
- **VGG16**: 138M parÃ¢metros, arquitetura clÃ¡ssica e robusta
- **MobileNetV2**: 3.5M parÃ¢metros, eficiente para dispositivos mÃ³veis

### 2. Feature Freezing

```python
# Congelamento das camadas convolucionais
for param in model.features.parameters():
    param.requires_grad = False
```

**Justificativa:** Com apenas ~1.600 imagens de treino, treinar todas as camadas causaria overfitting severo.

### 3. Arquitetura do Classificador

```python
model.classifier = nn.Sequential(
    nn.Linear(n_features, 256),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5),
    nn.Linear(256, 1)
)
```

**Design simplificado** para evitar overfitting em datasets pequenos.

### 4. OtimizaÃ§Ã£o e RegularizaÃ§Ã£o

| TÃ©cnica | Valor | Justificativa |
|---------|-------|---------------|
| **Optimizer** | AdamW | Melhor que Adam para regularizaÃ§Ã£o |
| **Learning Rate** | 5Ã—10â»âµ | Balanceamento entre convergÃªncia e estabilidade |
| **Weight Decay** | 1Ã—10â»â´ | RegularizaÃ§Ã£o L2 |
| **Dropout** | 0.5 | Previne co-adaptaÃ§Ã£o de neurÃ´nios |
| **Batch Size** | 32 | Compromisso entre memÃ³ria e convergÃªncia |

### 5. EstratÃ©gias de Treinamento

- **Early Stopping:** Patience de 7 Ã©pocas para evitar overfitting
- **Learning Rate Scheduler:** ReduceLROnPlateau (reduz LR quando val_loss estagnar)
- **Loss Function:** BCEWithLogitsLoss (estÃ¡vel numericamente)

---

## ğŸ—ï¸ Arquiteturas Comparadas

### VGG16

**CaracterÃ­sticas:**
- ğŸ“¦ 138 milhÃµes de parÃ¢metros
- ğŸ¯ Arquitetura clÃ¡ssica e bem estabelecida
- ğŸ”§ Camadas convolucionais profundas (13 conv + 3 FC)

**Vantagens:**
- âœ… Alta capacidade de aprendizado
- âœ… Features robustas para classificaÃ§Ã£o
- âœ… Muito estudada e testada

**Desvantagens:**
- âš ï¸ Pesada (>500MB)
- âš ï¸ InferÃªncia mais lenta

### MobileNetV2

**CaracterÃ­sticas:**
- ğŸ“¦ 3.5 milhÃµes de parÃ¢metros
- ğŸš€ Otimizada para eficiÃªncia
- ğŸ”§ Depthwise separable convolutions

**Vantagens:**
- âœ… Modelo leve (~14MB)
- âœ… InferÃªncia rÃ¡pida
- âœ… Ideal para dispositivos mÃ³veis

**Desvantagens:**
- âš ï¸ Menor capacidade que VGG16
- âš ï¸ Pode ter performance levemente inferior

---

## ğŸ“ˆ Resultados

### VGG16 - MÃ©tricas de ValidaÃ§Ã£o

- **AUC-ROC:** 0.989
- **Melhor Val Loss:** 0.2763
- **Ã‰pocas treinadas:** 29 (early stopping)

### VGG16 - Performance em Teste Real

| LÃ¢mina | Amostras | AcurÃ¡cia | Sensibilidade | Especificidade | TP | FP | TN | FN |
|--------|----------|----------|---------------|----------------|----|----|----|----|
| **18** | 320 | **86.3%** | 75.6% | **98.7%** | 130 | 2 | 146 | 42 |
| **19** | 167 | **94.6%** | **98.9%** | 90.0% | 86 | 8 | 72 | 1 |
| **20** | 248 | **93.2%** | 96.9% | 89.1% | 125 | 13 | 106 | 4 |
| **23** | 230 | **97.8%** | **100%** | 95.8% | 112 | 5 | 113 | 0 |
| **24** | 936 | **97.4%** | **99.8%** | 95.2% | 457 | 23 | 455 | 1 |
| **MÃ©dia** | - | **93.8%** | **94.2%** | **92.7%** | - | - | - | - |

### ğŸ“Š InterpretaÃ§Ã£o dos Resultados

**ğŸ¯ Sensibilidade (Recall) - 94.2%:**
- O modelo detecta **94 de cada 100** parasitas presentes
- Crucial para diagnÃ³stico: **poucos falsos negativos**
- LÃ¢mina 23: 100% de detecÃ§Ã£o!

**âœ… Especificidade - 92.7%:**
- O modelo corretamente identifica **93 de cada 100** amostras negativas
- Reduz trabalho de revisÃ£o manual de falsos positivos
- LÃ¢mina 18: 98.7% - excelente confiabilidade

**ğŸ“ˆ AcurÃ¡cia Geral - 93.8%:**
- Performance consistente em 4 de 5 lÃ¢minas (>93%)
- LÃ¢mina 18: 86.3% (possivelmente caracterÃ­sticas diferentes)

### ğŸ† Destaques por LÃ¢mina

- **LÃ¢mina 23:** Desempenho perfeito (100% sensibilidade, 0 falsos negativos)
- **LÃ¢mina 24:** Maior volume de dados (936 amostras), manteve 99.8% sensibilidade
- **LÃ¢mina 18:** Especificidade de 98.7% (apenas 2 falsos positivos)

### MobileNetV2 - Resultados

> ğŸš§ **Em desenvolvimento** - Resultados serÃ£o adicionados em breve

---

## ğŸ“ Estrutura do Projeto

```
Projeto-Trypanossoma/
â”‚
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ requirements.txt                   # DependÃªncias do projeto
â”œâ”€â”€ LICENSE                            # LicenÃ§a MIT
â”‚
â”œâ”€â”€ data/                              # Dados (nÃ£o incluÃ­dos no repositÃ³rio)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ lamina_18/
â”‚       â”œâ”€â”€ lamina_19/
â”‚       â”œâ”€â”€ lamina_20/
â”‚       â”œâ”€â”€ lamina_23/
â”‚       â””â”€â”€ lamina_24/
â”‚
â”œâ”€â”€ models/                            # Modelos treinados
â”‚   â”œâ”€â”€ vgg16_best_model.pth
â”‚   â””â”€â”€ mobilenetv2_best_model.pth
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_vgg16_training.ipynb
â”‚   â””â”€â”€ 03_mobilenetv2_training.ipynb
â”‚
â”œâ”€â”€ src/                               # CÃ³digo fonte
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py                     # Dataset e DataLoader
â”‚   â”œâ”€â”€ models.py                      # DefiniÃ§Ã£o dos modelos
â”‚   â”œâ”€â”€ train.py                       # Loop de treinamento
â”‚   â”œâ”€â”€ evaluate.py                    # AvaliaÃ§Ã£o e mÃ©tricas
â”‚   â””â”€â”€ utils.py                       # FunÃ§Ãµes auxiliares
â”‚
â”œâ”€â”€ results/                           # Resultados e visualizaÃ§Ãµes
â”‚   â”œâ”€â”€ training_curves/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â””â”€â”€ roc_curves/
â”‚
â””â”€â”€ docs/                              # DocumentaÃ§Ã£o adicional
    â”œâ”€â”€ methodology.md
    â””â”€â”€ experiment_log.md
```

---

## ğŸš€ Como Usar

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/Projeto-Trypanossoma.git
cd Projeto-Trypanossoma
```

### 2. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Preparar os Dados

Organize suas imagens seguindo a estrutura:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ positivo/
â”‚   â””â”€â”€ negativo/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ positivo/
â”‚   â””â”€â”€ negativo/
â””â”€â”€ test/
    â””â”€â”€ lamina_XX/
```

### 4. Treinar o Modelo

#### VGG16

```bash
python src/train.py --model vgg16 --epochs 50 --batch-size 32 --lr 5e-5
```

#### MobileNetV2

```bash
python src/train.py --model mobilenetv2 --epochs 50 --batch-size 32 --lr 5e-5
```

### 5. Avaliar no Teste

```bash
python src/evaluate.py --model vgg16 --checkpoint models/vgg16_best_model.pth --test-dir data/test/
```

### 6. Fazer PrediÃ§Ãµes em Novas Imagens

```python
from src.models import load_model
from src.utils import predict_image

model = load_model('vgg16', 'models/vgg16_best_model.pth')
result = predict_image(model, 'path/to/image.jpg')

print(f"PrediÃ§Ã£o: {'Positivo' if result > 0.5 else 'Negativo'}")
print(f"ConfianÃ§a: {result:.2%}")
```

---

## ğŸ“¦ Requisitos

```txt
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
Pillow>=9.5.0
tqdm>=4.65.0
```

**Sistema:**
- Python 3.8+
- CUDA 11.8+ (opcional, para GPU)
- 8GB RAM mÃ­nimo (16GB recomendado)

---

## ğŸ’¡ Desafios e SoluÃ§Ãµes

### ğŸ”¥ Problema 1: Overfitting Severo

**Sintoma:**
- Train loss caindo, mas validation loss subindo
- Gap crescente entre treino e validaÃ§Ã£o

**Causas Identificadas:**
1. âŒ Dataset aumentado prÃ©-gerado (imagens fixas)
2. âŒ BatchNorm com dataset pequeno causando ruÃ­do
3. âŒ Learning rate muito alto (1e-4)
4. âŒ Todas as camadas da VGG treinÃ¡veis

**SoluÃ§Ãµes Implementadas:**
1. âœ… Data augmentation on-the-fly (variaÃ§Ãµes infinitas)
2. âœ… RemoÃ§Ã£o do BatchNorm do classificador
3. âœ… ReduÃ§Ã£o do learning rate para 5e-5
4. âœ… Congelamento das features da VGG
5. âœ… Classificador simplificado (512 â†’ 256 features)
6. âœ… Dropout de 0.5
7. âœ… Weight decay de 1e-4

**Resultado:**
- Val loss estÃ¡vel e convergindo junto com train loss
- Gap mÃ­nimo entre as curvas
- AUC de 0.989

### ğŸ› Problema 2: Desalinhamento de Labels

**Sintoma:**
- Resultados inconsistentes e estranhos

**Causa:**
- Labels e imagens em ordens diferentes

**SoluÃ§Ã£o:**
```python
# Usar DataFrames para garantir alinhamento
df = pd.DataFrame({
    'filename': sorted(image_paths),
    'label': corresponding_labels
})
```

### âš¡ Problema 3: ConvergÃªncia Lenta

**Sintoma:**
- Modelo nÃ£o melhorando apÃ³s vÃ¡rias Ã©pocas

**Causa:**
- Learning rate muito baixo (1e-5) com BatchNorm

**SoluÃ§Ã£o:**
- Learning rate scheduler (ReduceLROnPlateau)
- ComeÃ§a com LR maior (5e-5), reduz quando estagnar

---

## ğŸ”® Trabalhos Futuros

- [ ] Implementar e comparar MobileNetV2
- [ ] Testar outras arquiteturas (ResNet, EfficientNet)
- [ ] Implementar ensemble de modelos
- [ ] Criar interface web com Gradio/Streamlit
- [ ] SegmentaÃ§Ã£o de parasitas (localizaÃ§Ã£o exata)
- [ ] QuantificaÃ§Ã£o automÃ¡tica de parasitemia
- [ ] DetecÃ§Ã£o de outros protozoÃ¡rios
- [ ] Deploy em dispositivo mÃ³vel (TFLite/ONNX)
- [ ] Explicabilidade com Grad-CAM
- [ ] Aumento do dataset com tÃ©cnicas de GAN

---

## ğŸ“š ReferÃªncias

1. World Health Organization. (2023). Chagas disease (American trypanosomiasis)
2. Simonyan, K., & Zisserman, A. (2014). Very Deep Convolutional Networks for Large-Scale Image Recognition
3. Sandler, M., et al. (2018). MobileNetV2: Inverted Residuals and Linear Bottlenecks
4. He, K., et al. (2016). Deep Residual Learning for Image Recognition

---

## ğŸ‘¨â€ğŸ’» Autor

**[Seu Nome]**

- ğŸ“ Doutorando em [Sua Ãrea]
- ğŸ’¼ LinkedIn: [seu-linkedin](https://linkedin.com/in/seu-perfil)
- ğŸ“§ Email: seu.email@exemplo.com
- ğŸ™ GitHub: [@seu-usuario](https://github.com/seu-usuario)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ™ Agradecimentos

- Dataset fornecido por [InstituiÃ§Ã£o/LaboratÃ³rio]
- Infraestrutura computacional: [GPU/Cloud provider]
- OrientaÃ§Ã£o: [Nome do orientador]

---

## ğŸ“Š Status do Projeto

![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow)

**Ãšltima atualizaÃ§Ã£o:** Janeiro 2026

---

<div align="center">

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!**

Made with â¤ï¸ and ğŸ Python

</div>
